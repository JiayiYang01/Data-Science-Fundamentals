{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Worksheet 06\n",
    "\n",
    "Name:  Jiayi Yang\n",
    "UID: U20886114\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Kmeans ++\n",
    "- Hierarchical Clustering\n",
    "\n",
    "### Kmeans ++\n",
    "\n",
    "a) What is the difference between K means and K means ++?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The primary difference between K-means and K-means++ is in the initialization of centroids. K-means++ is designed to improve the initialization step of K-means in a way that is likely to result in a better final clustering. In K-means, the initial centroids are chosen randomly, which can sometimes lead to poor clustering or slow convergence if the initial centroids are not well-placed. K-means++ chooses the initial centroids carefully to try to spread them out within the data space, which often leads to better and more consistent results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "b) What are some limitations of K means ++?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "It may not work well with clusters of different sizes and densities.\n",
    "It still requires the number of clusters to be specified in advance.\n",
    "It is sensitive to outliers since centroids can be pulled by outliers.\n",
    "It is not suitable for identifying clusters with non-convex shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "c) Interpret the silhouette plot below. It's a histogram where each bar corresponds to the silhouette score for that data point. Comment on which number of clusters K (2,3,4 or 5) you would choose and why. (the red dotted line is the average silhouette score over the entire dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"silhouette.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "K=2: The silhouette scores are mostly above the average, but there is a significant proportion of the dataset in one cluster with lower silhouette scores, indicating some misclassification or that a binary split is not the best representation of the data's structure.\n",
    "\n",
    "K=3: There's an improvement in the silhouette scores, with most of the data points above the average line, and the scores are more evenly distributed among the clusters.\n",
    "\n",
    "K=4: This configuration shows that some clusters have many points with scores lower than the average, which suggests that a four-cluster solution may not be fitting the data as well.\n",
    "\n",
    "K=5: There is a wide variance in scores within clusters, and some clusters have many points below the average score line, suggesting that this might be an over-segmentation of the data.\n",
    "\n",
    "Based on this analysis, K=3 seems to be the most appropriate number of clusters for the dataset. It has the highest average silhouette score, and the distribution of silhouette scores for each cluster is relatively even and above the average line, suggesting that the clusters are well-separated and internally cohesive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "Using the following dataset:\n",
    "\n",
    "| Point | x | y |\n",
    "|-------|---|---|\n",
    "| A     | 0 | 0 |\n",
    "| B     | 1 | 1 |\n",
    "| C     | 3 | 0 |\n",
    "| D     | 0 | 1 |\n",
    "| E     | 2 | 2 |\n",
    "\n",
    "with\n",
    "\n",
    "d = Euclidean  \n",
    "D = Single-Link\n",
    "\n",
    "produce the distance matrix at every step of the hierarchical clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 1\n",
    "\n",
    "|   | A | B | C | D | E |\n",
    "|---|---|---|---|---|---|\n",
    "| A | 0 |1.41|3|1|2.83 |\n",
    "| B |1.41| 0 |2.24|1|1.41|\n",
    "| C | 3 |2.24| 0 |3.16|2.24|\n",
    "| D | 1 | 1 |3.16| 0 |2.24|\n",
    "| E |2.83|1.41|2.24|2.24| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 2\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "|   | 0 |2.24|1.41|1|\n",
    "|   |2.24| 0 |2.24| 3 |\n",
    "|   |1.41|2.24| 0 |2.24|\n",
    "|   | 1 | 3 |2.24| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 3\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "|   | 0 |2.24|2.24|\n",
    "|   |2.24| 0 |1.41|\n",
    "|   |2.24|1.41| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 4\n",
    "\n",
    "|   |   |   |\n",
    "|---|---|---|\n",
    "|   | 0 |2.24|\n",
    "|   |2.24| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Repeat the above with\n",
    "\n",
    "d = Euclidean  \n",
    "D = Complete-Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 1\n",
    "\n",
    "|   | A | B | C | D | E |\n",
    "|---|---|---|---|---|---|\n",
    "| A | 0 |1.41|3|1|2.83 |\n",
    "| B |1.41| 0 |2.24|1|1.41|\n",
    "| C | 3 |2.24| 0 |3.16|2.24|\n",
    "| D | 1 | 1 |3.16| 0 |2.24|\n",
    "| E |2.83|1.41|2.24|2.24| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 2\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "|   | 0 |2.24|1.41|1.41|\n",
    "|   |2.24| 0 |2.24|3.16|\n",
    "|   |1.41|2.24| 0 |2.83|\n",
    "|   |1.41|3.16|2.83| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 3\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "|   | 0 |3.16|2.24|\n",
    "|   |3.16| 0 |2.83|\n",
    "|   |2.24|2.83| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Step 4\n",
    "\n",
    "|   |   |   |\n",
    "|---|---|---|\n",
    "|   | 0 |3.16|\n",
    "|   |3.16| 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Challenge Problem\n",
    "\n",
    "### Input:\n",
    "- Some DNA sequences, each sequence is on a new line. All sequences are of equal length and consist of characters from the set {A, C, G, T}.\n",
    "\n",
    "\n",
    "### Task:\n",
    "- Implement a hierarchical clustering algorithm using Hamming distance as the metric clustering DNA sequences.\n",
    "\n",
    "### Definition of Hamming Distance:\n",
    "\n",
    "The Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. Mathematically, if we have two strings, $s$ and $t$, of equal length, then the Hamming distance $H(s, t)$ is given by:\n",
    "\n",
    "$$ H(s, t) = \\sum_{i=1}^{n} [s_i \\neq t_i] $$\n",
    "\n",
    "where $n$ is the length of the strings, $s_i$ and $t_i$ are the characters at position $i$ in $s$ and $t$ respectively, and $[s_i \\neq t_i]$ is an indicator function, equal to 1 if $s_i \\neq t_i$ and 0 otherwise.\n",
    "\n",
    "\n",
    "### Guidelines:\n",
    "1. **Read the Dataset**: Choose appropriate data structure.\n",
    "2. **Compute Hamming Distance**: Implement a function to calculate the Hamming distance between any two sequences.\n",
    "3. **Hierarchical Clustering**: Apply the hierarchical clustering algorithm using the single-linkage method.\n",
    "4. **Dendrogram**: Generate a dendrogram to visualize the clustering.\n",
    "5. **NOTE**: You may use any Python library, but be sure to understand the underlying algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [\n",
    " 'ACGTGGTCTTAA',\n",
    " 'ACGTCGTCTTAC',\n",
    " 'ACGTGGTCTTAC',\n",
    " 'ACGTAGTCTTAA',\n",
    " 'ACGTGGTCTTCC',\n",
    " 'ACGTGGTCTTAG',\n",
    " 'CTGTTAAATAAG',\n",
    " 'GGTTAGAACACG',\n",
    " 'AGTGGTTGAAGT',\n",
    " 'GGCTTACACCCT',\n",
    " 'AGATTGTCCACT',\n",
    " 'CATGCGGTCAAC',\n",
    " 'ATATATCATAGC',\n",
    " 'TTTGCGGTTGGA',\n",
    " 'GAATGGTCAGAA',\n",
    " 'GTGATGCTGTCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def hamming_distance(seq1, seq2):\n",
    "    assert len(seq1) == len(seq2), \"Sequences must be of equal length.\"\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(seq1, seq2))\n",
    "\n",
    "# Compute the initial distance matrix using Hamming distance\n",
    "hamming_distances = pdist(sequences, hamming_distance)\n",
    "hamming_distance_matrix = squareform(hamming_distances)\n",
    "\n",
    "# Perform hierarchical clustering using single-linkage method\n",
    "Z_hamming = linkage(hamming_distances, method='single')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z_hamming, labels=sequences, orientation='right')\n",
    "plt.title('Hierarchical Clustering Dendrogram (Hamming distance)')\n",
    "plt.xlabel('Hamming Distance')\n",
    "plt.ylabel('DNA Sequences')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def compute_hamming_distance_matrix(sequences):\n",
    "    \"\"\"Compute the Hamming distance matrix for a list of DNA sequences.\"\"\"\n",
    "    n = len(sequences)\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance_matrix[i, j] = hamming_distance(sequences[i], sequences[j])\n",
    "            distance_matrix[j, i] = distance_matrix[i, j]\n",
    "    return distance_matrix\n",
    "\n",
    "# Calculate the distance matrix for the DNA sequences\n",
    "distance_matrix = compute_hamming_distance_matrix(sequences)\n",
    "\n",
    "# Perform hierarchical clustering using the distance matrix\n",
    "Z_hamming_custom = linkage(distance_matrix, method='complete')\n",
    "\n",
    "# Plot the dendrogram for the hierarchical clustering\n",
    "plt.figure(figsize=(10, 8))\n",
    "dendrogram(Z_hamming_custom, labels=sequences, orientation='right')\n",
    "plt.title('Hierarchical Clustering Dendrogram (Hamming distance)')\n",
    "plt.xlabel('Hamming Distance')\n",
    "plt.ylabel('DNA Sequences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
